{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbixQhmb0gdH",
        "outputId": "75c68963-2d20-433d-f12d-8809d3b98f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP0p1Cqy0iBY",
        "outputId": "b1d0cd10-52d7-44d6-bd75-b0f39bb02cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox6aFG2J0h-D",
        "outputId": "bfa248c3-aa65-4ca5-f728-3145e6dcf60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new-plant-diseases-dataset.zip -d /content/plant_disease_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRHFLoZ50h7o",
        "outputId": "14a84c08-e63e-4d8d-b9b5-902782d9690d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open new-plant-diseases-dataset.zip, new-plant-diseases-dataset.zip.zip or new-plant-diseases-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "val_dir   = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "test_dir  = '/content/plant_disease_dataset/test/test'"
      ],
      "metadata": {
        "id": "AEbL0JlC0h5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# --- COLAB SETUP: MIXED PRECISION & GPU CHECK ---\n",
        "\n",
        "try:\n",
        "    # Use mixed precision for faster training on modern GPUs (T4, V100, A100)\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    print(\"Mixed precision policy set to 'mixed_float16'. Training will be faster.\")\n",
        "except:\n",
        "    print(\"Mixed precision setup failed (likely older GPU/CPU). Using default float32.\")\n",
        "\n",
        "# Verify GPU availability\n",
        "if tf.test.is_gpu_available():\n",
        "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "else:\n",
        "    print(\"WARNING: GPU not detected. Training will be extremely slow. Please enable a GPU runtime.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI9SwSMQ0h24",
        "outputId": "e5b77412-a9a1-41a4-d4d9-7a2a4bda2840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-1084916246.py:21: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed precision policy set to 'mixed_float16'. Training will be faster.\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. CONFIGURATION ---\n",
        "\n",
        "TARGET_SIZE = (224, 224) # Standard input size for MobileNetV2\n",
        "BATCH_SIZE = 64\n",
        "INITIAL_LR = 1e-3 # High LR for training the new head (Phase 1)\n",
        "FINE_TUNE_LR = 1e-5 # Very low LR for fine-tuning the base (Phase 2)\n",
        "INITIAL_EPOCHS = 3 # Sufficient to stabilize the new head\n",
        "FINE_TUNE_EPOCHS = 3 # Longer duration for delicate fine-tuning\n",
        "TOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
        "NUM_FINE_TUNE_LAYERS = 50 # Unfreeze the last 50 layers of the base model\n",
        "\n",
        "# --- IMPORTANT: Placeholder directories (UPDATE THESE PATHS) ---\n",
        "train_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "val_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "test_dir = '/content/plant_disease_dataset/test/test'\n",
        "MODEL_SAVE_PATH = 'best_plant_disease_model.keras'\n",
        "\n",
        "print(f\"\\nTarget Image Size: {TARGET_SIZE}\")\n",
        "print(f\"Training Plan: Phase 1 (Frozen) = {INITIAL_EPOCHS} epochs, Phase 2 (Fine-Tuned) = {FINE_TUNE_EPOCHS} epochs.\")\n",
        "\n",
        "\n",
        "# --- 2. DATA AUGMENTATION & GENERATORS ---\n",
        "\n",
        "# Extensive Augmentation (Anti-Overfitting Measure 1)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30, # Increased range\n",
        "    width_shift_range=0.25,\n",
        "    height_shift_range=0.25,\n",
        "    shear_range=0.25,\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.7, 1.3]\n",
        ")\n",
        "\n",
        "# Only rescaling for validation/test data\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "try:\n",
        "    # Training Generator\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Validation Generator\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Test Generator\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    NUM_CLASSES = train_generator.num_classes\n",
        "\n",
        "    # Calculate steps robustly\n",
        "    STEPS_PER_EPOCH = int(np.ceil(train_generator.samples / BATCH_SIZE))\n",
        "    VALIDATION_STEPS = int(np.ceil(val_generator.samples / BATCH_SIZE))\n",
        "    TEST_STEPS = int(np.ceil(test_generator.samples / BATCH_SIZE))\n",
        "    print(f\"Detected {NUM_CLASSES} classes.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- DATA LOAD ERROR: Ensure paths are correct ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    # Fallback to avoid crash during execution setup\n",
        "    NUM_CLASSES = 38\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    VALIDATION_STEPS = 10\n",
        "    TEST_STEPS = 10\n",
        "    print(f\"Using placeholder classes={NUM_CLASSES}. Please check your dataset paths.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnQbhnc90h0e",
        "outputId": "92e3f7ad-f602-487a-d23d-ab424b4df315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Image Size: (224, 224)\n",
            "Training Plan: Phase 1 (Frozen) = 3 epochs, Phase 2 (Fine-Tuned) = 3 epochs.\n",
            "\n",
            "--- DATA LOAD ERROR: Ensure paths are correct ---\n",
            "Error details: [Errno 2] No such file or directory: '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
            "Using placeholder classes=38. Please check your dataset paths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. MOBILE NET V2 MODEL WITH OPTIMIZED HEAD ---\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(*TARGET_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Initially, freeze ALL pre-trained layers.\n",
        "base_model.trainable = False\n",
        "\n",
        "# Optimized Classification Head (Anti-Overfitting Measure 2: L2 Reg & Dropout)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)), # L2 Regularization (Penalizes large weights)\n",
        "    Dropout(0.6), # Increased dropout to 60% for aggressive overfitting prevention\n",
        "    Dense(NUM_CLASSES, activation='softmax', dtype='float32') # Use float32 for the output layer\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYJgnPKE0hyK",
        "outputId": "eba112f6-0004-4895-956b-a78c3e940c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. CALLBACKS FOR ROBUST TRAINING ---\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True, # Restores the model with the lowest validation loss\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-7, # Allows the LR to drop very low\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=MODEL_SAVE_PATH,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max', # Save model when validation accuracy is highest\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, lr_scheduler, model_checkpoint]"
      ],
      "metadata": {
        "id": "PYM67OJP1ZB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. INITIAL TRAINING (Phase 1: Frozen Base) ---\n",
        "\n",
        "print(\"\\n--- Phase 1: Training Classification Head (Frozen MobileNetV2) ---\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_frozen = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=INITIAL_EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "DUzsB4cW1Y_a",
        "outputId": "939b7355-c1b5-42e4-ac80-7bf999d3bf37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 1: Training Classification Head (Frozen MobileNetV2) ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1919855833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m history_frozen = model.fit(\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINITIAL_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. FINE-TUNING SETUP (Transition) ---\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning Phase Setup (Unfreezing Layers) ---\")\n",
        "\n",
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the last NUM_FINE_TUNE_LAYERS\n",
        "for layer in base_model.layers[:-NUM_FINE_TUNE_LAYERS]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compile the model with a tiny LR\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(f\"Model re-compiled with low learning rate ({FINE_TUNE_LR}) for fine-tuning.\")"
      ],
      "metadata": {
        "id": "M2a97FiB1Y9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. FINE-TUNING TRAINING (Phase 2) ---\n",
        "\n",
        "print(\"\\n--- Phase 2: Fine-Tuning Top Layers ---\")\n",
        "\n",
        "# Continue training for the remaining epochs\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=TOTAL_EPOCHS,\n",
        "    initial_epoch=INITIAL_EPOCHS, # Start where Phase 1 left off\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")"
      ],
      "metadata": {
        "id": "7QaPkvTj1Y7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights saved by the ModelCheckpoint for final evaluation\n",
        "if os.path.exists(MODEL_SAVE_PATH):\n",
        "    model.load_weights(MODEL_SAVE_PATH)\n",
        "    print(f\"Loaded best model weights from: {MODEL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(\"Warning: Model checkpoint file not found. Using final trained weights.\")\n",
        "\n",
        "# Evaluate the final model accuracy on the test set\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=TEST_STEPS)\n",
        "print(f\"Final Test Accuracy (with best weights loaded): {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Vy_bomXK1Y5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeW24SBm1Y2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0lIjQTG1Y0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTYUEEi01YyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}