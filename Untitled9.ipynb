{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJdNVohmWPtx",
        "outputId": "2f60679e-2670-4e62-db44-25903ae456f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "aX4QEgsMWZ7I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d vipoooool/new-plant-diseases-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI0seXFaWZ9i",
        "outputId": "a7a21ef1-b758-427e-c48f-866321ef7122"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading new-plant-diseases-dataset.zip to /content\n",
            " 99% 2.67G/2.70G [00:29<00:00, 196MB/s]\n",
            "100% 2.70G/2.70G [00:29<00:00, 98.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q new-plant-diseases-dataset.zip -d /content/plant_disease_dataset"
      ],
      "metadata": {
        "id": "T9BKdDLxWZ_j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "val_dir   = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "test_dir  = '/content/plant_disease_dataset/test/test'"
      ],
      "metadata": {
        "id": "x6UrNFJ2WaB0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# --- COLAB SETUP: MIXED PRECISION & GPU CHECK ---\n",
        "\n",
        "try:\n",
        "    # Use mixed precision for faster training on modern GPUs (T4, V100, A100)\n",
        "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "    print(\"Mixed precision policy set to 'mixed_float16'. Training will be faster.\")\n",
        "except:\n",
        "    print(\"Mixed precision setup failed (likely older GPU/CPU). Using default float32.\")\n",
        "\n",
        "# Verify GPU availability\n",
        "if tf.test.is_gpu_available():\n",
        "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "else:\n",
        "    print(\"WARNING: GPU not detected. Training will be extremely slow. Please enable a GPU runtime.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5185bjWWaD4",
        "outputId": "bfd2ee0f-5ed2-4237-d7e6-6977d5728fd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tmp/ipython-input-1084916246.py:21: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mixed precision policy set to 'mixed_float16'. Training will be faster.\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. CONFIGURATION ---\n",
        "\n",
        "TARGET_SIZE = (224, 224) # Standard input size for MobileNetV2\n",
        "BATCH_SIZE = 64\n",
        "INITIAL_LR = 1e-3 # High LR for training the new head (Phase 1)\n",
        "FINE_TUNE_LR = 1e-5 # Very low LR for fine-tuning the base (Phase 2)\n",
        "INITIAL_EPOCHS = 3 # Sufficient to stabilize the new head\n",
        "FINE_TUNE_EPOCHS = 3 # Longer duration for delicate fine-tuning\n",
        "TOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
        "NUM_FINE_TUNE_LAYERS = 50 # Unfreeze the last 50 layers of the base model\n",
        "\n",
        "# --- IMPORTANT: Placeholder directories (UPDATE THESE PATHS) ---\n",
        "train_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "val_dir = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid'\n",
        "test_dir = '/content/plant_disease_dataset/test/test'\n",
        "MODEL_SAVE_PATH = 'best_plant_disease_model.keras'\n",
        "\n",
        "print(f\"\\nTarget Image Size: {TARGET_SIZE}\")\n",
        "print(f\"Training Plan: Phase 1 (Frozen) = {INITIAL_EPOCHS} epochs, Phase 2 (Fine-Tuned) = {FINE_TUNE_EPOCHS} epochs.\")\n",
        "\n",
        "\n",
        "# --- 2. DATA AUGMENTATION & GENERATORS ---\n",
        "\n",
        "# Extensive Augmentation (Anti-Overfitting Measure 1)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30, # Increased range\n",
        "    width_shift_range=0.25,\n",
        "    height_shift_range=0.25,\n",
        "    shear_range=0.25,\n",
        "    zoom_range=0.25,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.7, 1.3]\n",
        ")\n",
        "\n",
        "# Only rescaling for validation/test data\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "try:\n",
        "    # Training Generator\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Validation Generator\n",
        "    val_generator = val_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Test Generator\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=TARGET_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "    NUM_CLASSES = train_generator.num_classes\n",
        "\n",
        "    # Calculate steps robustly\n",
        "    STEPS_PER_EPOCH = int(np.ceil(train_generator.samples / BATCH_SIZE))\n",
        "    VALIDATION_STEPS = int(np.ceil(val_generator.samples / BATCH_SIZE))\n",
        "    TEST_STEPS = int(np.ceil(test_generator.samples / BATCH_SIZE))\n",
        "    print(f\"Detected {NUM_CLASSES} classes.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- DATA LOAD ERROR: Ensure paths are correct ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    # Fallback to avoid crash during execution setup\n",
        "    NUM_CLASSES = 38\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    VALIDATION_STEPS = 10\n",
        "    TEST_STEPS = 10\n",
        "    print(f\"Using placeholder classes={NUM_CLASSES}. Please check your dataset paths.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-lZP8B5XBgq",
        "outputId": "6b3a51d1-7f79-4407-ebb4-a1d9f846b431"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target Image Size: (224, 224)\n",
            "Training Plan: Phase 1 (Frozen) = 3 epochs, Phase 2 (Fine-Tuned) = 3 epochs.\n",
            "Found 70295 images belonging to 38 classes.\n",
            "Found 17572 images belonging to 38 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "Detected 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. MOBILE NET V2 MODEL WITH OPTIMIZED HEAD ---\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(*TARGET_SIZE, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Initially, freeze ALL pre-trained layers.\n",
        "base_model.trainable = False\n",
        "\n",
        "# Optimized Classification Head (Anti-Overfitting Measure 2: L2 Reg & Dropout)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)), # L2 Regularization (Penalizes large weights)\n",
        "    Dropout(0.6), # Increased dropout to 60% for aggressive overfitting prevention\n",
        "    Dense(NUM_CLASSES, activation='softmax', dtype='float32') # Use float32 for the output layer\n",
        "])\n"
      ],
      "metadata": {
        "id": "vTcoBP5cXBi1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. CALLBACKS FOR ROBUST TRAINING ---\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True, # Restores the model with the lowest validation loss\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    min_lr=1e-7, # Allows the LR to drop very low\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=MODEL_SAVE_PATH,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max', # Save model when validation accuracy is highest\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, lr_scheduler, model_checkpoint]"
      ],
      "metadata": {
        "id": "ENHkzZJrXBmW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. INITIAL TRAINING (Phase 1: Frozen Base) ---\n",
        "\n",
        "print(\"\\n--- Phase 1: Training Classification Head (Frozen MobileNetV2) ---\")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=INITIAL_LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_frozen = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=INITIAL_EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvW6LCDxXdps",
        "outputId": "f90a6ad8-321c-4ae2-ef73-a6ccb8126d4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Phase 1: Training Classification Head (Frozen MobileNetV2) ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888ms/step - accuracy: 0.5905 - loss: 1.9458\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87412, saving model to best_plant_disease_model.keras\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1078s\u001b[0m 951ms/step - accuracy: 0.5907 - loss: 1.9453 - val_accuracy: 0.8741 - val_loss: 0.6973 - learning_rate: 0.0010\n",
            "Epoch 2/3\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876ms/step - accuracy: 0.7929 - loss: 0.9352\n",
            "Epoch 2: val_accuracy improved from 0.87412 to 0.89324, saving model to best_plant_disease_model.keras\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m996s\u001b[0m 906ms/step - accuracy: 0.7929 - loss: 0.9352 - val_accuracy: 0.8932 - val_loss: 0.5973 - learning_rate: 0.0010\n",
            "Epoch 3/3\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864ms/step - accuracy: 0.8019 - loss: 0.8803\n",
            "Epoch 3: val_accuracy did not improve from 0.89324\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m981s\u001b[0m 893ms/step - accuracy: 0.8019 - loss: 0.8803 - val_accuracy: 0.8868 - val_loss: 0.6101 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. FINE-TUNING SETUP (Transition) ---\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning Phase Setup (Unfreezing Layers) ---\")\n",
        "\n",
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the last NUM_FINE_TUNE_LAYERS\n",
        "for layer in base_model.layers[:-NUM_FINE_TUNE_LAYERS]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compile the model with a tiny LR\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(f\"Model re-compiled with low learning rate ({FINE_TUNE_LR}) for fine-tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S37iHFCjiEde",
        "outputId": "889d8e67-2a09-4cd8-afe9-b552cb09afdb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Fine-Tuning Phase Setup (Unfreezing Layers) ---\n",
            "Model re-compiled with low learning rate (1e-05) for fine-tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. FINE-TUNING TRAINING (Phase 2) ---\n",
        "\n",
        "print(\"\\n--- Phase 2: Fine-Tuning Top Layers ---\")\n",
        "\n",
        "# Continue training for the remaining epochs\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=TOTAL_EPOCHS,\n",
        "    initial_epoch=INITIAL_EPOCHS, # Start where Phase 1 left off\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"\\n--- Training Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU2prYZAiHfx",
        "outputId": "f6c8e0aa-41a2-4c88-b86d-1b285f21acb7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Phase 2: Fine-Tuning Top Layers ---\n",
            "Epoch 4/6\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907ms/step - accuracy: 0.7099 - loss: 1.2074\n",
            "Epoch 4: val_accuracy improved from 0.89324 to 0.89586, saving model to best_plant_disease_model.keras\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1103s\u001b[0m 958ms/step - accuracy: 0.7100 - loss: 1.2072 - val_accuracy: 0.8959 - val_loss: 0.5780 - learning_rate: 1.0000e-05\n",
            "Epoch 5/6\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870ms/step - accuracy: 0.8680 - loss: 0.6662\n",
            "Epoch 5: val_accuracy improved from 0.89586 to 0.93370, saving model to best_plant_disease_model.keras\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 901ms/step - accuracy: 0.8680 - loss: 0.6661 - val_accuracy: 0.9337 - val_loss: 0.4592 - learning_rate: 1.0000e-05\n",
            "Epoch 6/6\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881ms/step - accuracy: 0.9035 - loss: 0.5602\n",
            "Epoch 6: val_accuracy improved from 0.93370 to 0.94725, saving model to best_plant_disease_model.keras\n",
            "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1001s\u001b[0m 911ms/step - accuracy: 0.9035 - loss: 0.5602 - val_accuracy: 0.9472 - val_loss: 0.4158 - learning_rate: 1.0000e-05\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "--- Training Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# 1. Save Label Data using Pickle (RECOMMENDED)\n",
        "# Assuming 'train_generator' is available and has 'class_indices'\n",
        "try:\n",
        "    # Map index (0, 1, 2...) back to class name ('Apple_scab', etc.)\n",
        "    idx_to_class = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "    PICKLE_FILE_PATH = 'class_indices.pkl'\n",
        "    with open(PICKLE_FILE_PATH, 'wb') as f:\n",
        "        pickle.dump(idx_to_class, f)\n",
        "    print(f\"Label data (idx_to_class) saved successfully to {PICKLE_FILE_PATH} using pickle.\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"ERROR: 'train_generator' is not defined. Please run Section 2 first to generate class labels.\")\n",
        "\n",
        "\n",
        "# 2. Save the Model (BEST PRACTICE: Keras Format)\n",
        "# This model saving method is already used in Section 4.3, but shown here for reference.\n",
        "# It saves the architecture, weights, and optimizer state reliably.\n",
        "\n",
        "FINAL_MODEL_PATH = 'final_plant_disease_model.keras'\n",
        "# Assuming 'model' variable holds your trained Keras model\n",
        "if 'model' in locals():\n",
        "    model.save(FINAL_MODEL_PATH)\n",
        "    print(f\"Keras Model saved successfully to: {FINAL_MODEL_PATH}\")\n",
        "else:\n",
        "    print(\"ERROR: 'model' object not found. Ensure training is complete.\")\n",
        "\n",
        "\n",
        "# --- Warning Against Pickling the Model Itself ---\n",
        "\n",
        "# If you absolutely must use pickle for a Keras model (HIGHLY DISCOURAGED):\n",
        "# import pickle\n",
        "# with open('model_unsafe.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n",
        "# print(\"WARNING: The Keras model was saved using unsafe pickle. Use Keras .keras format instead.\")\n"
      ],
      "metadata": {
        "id": "KlrfQpA3Xdxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4546f4e6-5597-4066-9762-d5cddeceff2a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label data (idx_to_class) saved successfully to class_indices.pkl using pickle.\n",
            "Keras Model saved successfully to: final_plant_disease_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- EXTRACT AND SAVE CLASS LABELS ---\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Get class names from the training generator\n",
        "# The class_indices attribute maps class names to indices\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "class_labels = {i: name for i, name in enumerate(class_names)}\n",
        "\n",
        "print(f\"\\n✅ Found {len(class_labels)} disease classes:\")\n",
        "for idx, name in class_labels.items():\n",
        "    print(f\"  {idx}: {name}\")\n",
        "\n",
        "# Save labels to a pickle file\n",
        "with open('disease_labels.pkl', 'wb') as f:\n",
        "    pickle.dump(class_labels, f)\n",
        "\n",
        "print(\"\\n✅ Labels saved to 'disease_labels.pkl'\")\n",
        "\n",
        "# Download from Colab\n",
        "from google.colab import files\n",
        "files.download('disease_labels.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "Ts14WoARIKz_",
        "outputId": "801696c5-e9fb-4399-fc08-4c51bfb450b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Found 38 disease classes:\n",
            "  0: Apple___Apple_scab\n",
            "  1: Apple___Black_rot\n",
            "  2: Apple___Cedar_apple_rust\n",
            "  3: Apple___healthy\n",
            "  4: Blueberry___healthy\n",
            "  5: Cherry_(including_sour)___Powdery_mildew\n",
            "  6: Cherry_(including_sour)___healthy\n",
            "  7: Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
            "  8: Corn_(maize)___Common_rust_\n",
            "  9: Corn_(maize)___Northern_Leaf_Blight\n",
            "  10: Corn_(maize)___healthy\n",
            "  11: Grape___Black_rot\n",
            "  12: Grape___Esca_(Black_Measles)\n",
            "  13: Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
            "  14: Grape___healthy\n",
            "  15: Orange___Haunglongbing_(Citrus_greening)\n",
            "  16: Peach___Bacterial_spot\n",
            "  17: Peach___healthy\n",
            "  18: Pepper,_bell___Bacterial_spot\n",
            "  19: Pepper,_bell___healthy\n",
            "  20: Potato___Early_blight\n",
            "  21: Potato___Late_blight\n",
            "  22: Potato___healthy\n",
            "  23: Raspberry___healthy\n",
            "  24: Soybean___healthy\n",
            "  25: Squash___Powdery_mildew\n",
            "  26: Strawberry___Leaf_scorch\n",
            "  27: Strawberry___healthy\n",
            "  28: Tomato___Bacterial_spot\n",
            "  29: Tomato___Early_blight\n",
            "  30: Tomato___Late_blight\n",
            "  31: Tomato___Leaf_Mold\n",
            "  32: Tomato___Septoria_leaf_spot\n",
            "  33: Tomato___Spider_mites Two-spotted_spider_mite\n",
            "  34: Tomato___Target_Spot\n",
            "  35: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
            "  36: Tomato___Tomato_mosaic_virus\n",
            "  37: Tomato___healthy\n",
            "\n",
            "✅ Labels saved to 'disease_labels.pkl'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78f3d01e-c4e9-4bb2-9a3f-4e9598dc50c6\", \"disease_labels.pkl\", 1152)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# --- LOAD MODEL AND LABELS ---\n",
        "\n",
        "# Load the saved model\n",
        "# Ensure the model file path is correct\n",
        "MODEL_SAVE_PATH = 'best_plant_disease_model.keras' # Or 'final_plant_disease_model.keras'\n",
        "model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "\n",
        "# Load the class labels\n",
        "# Ensure the labels file path is correct\n",
        "PICKLE_FILE_PATH = 'disease_labels.pkl' # Or 'class_indices.pkl'\n",
        "with open(PICKLE_FILE_PATH, 'rb') as f:\n",
        "    class_labels = pickle.load(f)\n",
        "\n",
        "print(\"Model and class labels loaded successfully.\")\n",
        "\n",
        "# --- IMAGE PREPROCESSING AND PREDICTION ---\n",
        "\n",
        "# Set the path to your input image file\n",
        "# IMPORTANT: Upload your image to Colab and replace the path below\n",
        "image_path = '/content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Orange___Haunglongbing_(Citrus_greening)/09879f50-9755-442a-b725-b6358a654db1___CREC_HLB 5132.JPG' # <<<--- REPLACE WITH THE PATH TO YOUR IMAGE FILE\n",
        "\n",
        "# Ensure TARGET_SIZE is defined (from your configuration cell)\n",
        "# If not defined, you can set it manually here: TARGET_SIZE = (224, 224)\n",
        "if 'TARGET_SIZE' not in globals():\n",
        "    TARGET_SIZE = (224, 224)\n",
        "    print(f\"TARGET_SIZE not found in global variables, using default: {TARGET_SIZE}\")\n",
        "\n",
        "if image_path:\n",
        "    try:\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(image_path):\n",
        "            raise FileNotFoundError(f\"Image file not found at: {image_path}\")\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = Image.open(image_path)\n",
        "        img = img.resize(TARGET_SIZE)\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # Ensure the image has 3 channels (RGB) if it's grayscale or has an alpha channel\n",
        "        if len(img_array.shape) == 2: # Grayscale\n",
        "             img_array = np.stack((img_array,)*3, axis=-1)\n",
        "        elif img_array.shape[-1] == 4: # Has alpha channel\n",
        "             img_array = img_array[..., :3] # Take only RGB channels\n",
        "\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "        img_array = img_array / 255.0  # Rescale to [0, 1]\n",
        "\n",
        "        # Make a prediction\n",
        "        predictions = model.predict(img_array)\n",
        "\n",
        "        # Get the predicted class index\n",
        "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "        # Get the predicted class label\n",
        "        predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "        # Get the confidence score\n",
        "        confidence = predictions[0][predicted_class_index]\n",
        "\n",
        "        print(f\"\\nImage Path: {image_path}\")\n",
        "        print(f\"Predicted class index: {predicted_class_index}\")\n",
        "        print(f\"Predicted class label: {predicted_class_label}\")\n",
        "        print(f\"Confidence: {confidence:.2f}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during prediction: {e}\")\n",
        "else:\n",
        "    print(\"Please provide the path to your image in the 'image_path' variable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "binv0XbLIK3c",
        "outputId": "bd88d617-7ea2-4e52-f7e3-98bc2ceaccec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and class labels loaded successfully.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step\n",
            "\n",
            "Image Path: /content/plant_disease_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Orange___Haunglongbing_(Citrus_greening)/09879f50-9755-442a-b725-b6358a654db1___CREC_HLB 5132.JPG\n",
            "Predicted class index: 15\n",
            "Predicted class label: Orange___Haunglongbing_(Citrus_greening)\n",
            "Confidence: 1.00\n"
          ]
        }
      ]
    }
  ]
}